{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import directory_functions as dirfuncs\n",
    "import gather_middleware_statistics as gmws\n",
    "import gather_memtier_statistics as gmts\n",
    "import cut_away_warmup_cooldown as cut\n",
    "import math\n",
    "exp_dir = \"/home/flo/Documents/eth-asl-final-experiment-data/exp4/4_detailedrun_two_2017-11-29_165453\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get response times from MW for 6 multigets\n",
    "def gather_requests(exp_dir, reps, middlewares):\n",
    "    all_reps = []\n",
    "    for rep in reps:\n",
    "\n",
    "        middleware_dirs = [dirfuncs.get_only_subdir(os.path.join(exp_dir, str(rep), mw_dir)) for mw_dir in middlewares]\n",
    "        concatenated_requests = [gmws.concatenate_requestlogs(middleware_dir) for middleware_dir in middleware_dirs]\n",
    "\n",
    "\n",
    "        \n",
    "        metrics = [gmws.extract_metrics(reqs) for reqs in concatenated_requests]\n",
    "\n",
    "\n",
    "        cut_metrics = [cut.cut_away_warmup_cooldown(mets, 10, 72) for mets in metrics]\n",
    "\n",
    "        all_reps.extend(cut_metrics)\n",
    "        \n",
    "    return pd.concat(all_reps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What should be the granularity of the memtier response time interpolation?\n",
    "granularity = 0.1\n",
    "\n",
    "# Extract GET histogram from single memtier logfile\n",
    "def parse_line(line):\n",
    "    split = line.split()\n",
    "    return (split[1], split[2])\n",
    "def extract_GET_histogram(client_logfile_path):\n",
    "    with open(client_logfile_path, \"r\") as logfile:\n",
    "        return [parse_line(line)for line in logfile if line.startswith(\"SET\")]\n",
    "def extract_GET_throughput(client_logfile_path):\n",
    "    with open(client_logfile_path, \"r\") as logfile:\n",
    "        for line in logfile:\n",
    "            if line.startswith(\"Sets\"):\n",
    "                split_line = line.split()\n",
    "                return float(split_line[1])\n",
    "def interpolate_histogram(hist, granularity):\n",
    "    rowcount = hist.shape[0]\n",
    "    desired_steps = np.arange(start=hist[0, 0], stop=hist[rowcount-1, 0], step=granularity)\n",
    "    return desired_steps, np.interp(desired_steps, hist[:,0], hist[:,1])\n",
    "def calculate_numrequests(interpolated, xput, granularity):\n",
    "    interpolated = np.vstack(interpolated).transpose()\n",
    "    sorted = interpolated[interpolated[:,0].argsort()]\n",
    "\n",
    "    shifted = np.hstack([sorted[:-1,:], sorted[1:,:]])\n",
    "    shifted_frame = pd.DataFrame(data=shifted, columns=['responsetime_unshifted', 'percentile_unshifted', 'responsetime', 'percentile'])\n",
    "    shifted_frame['num_requests'] = shifted_frame['percentile'] * xput / 100\n",
    "    shifted_frame['num_requests_unshifted'] = shifted_frame['percentile_unshifted'] * xput / 100\n",
    "    shifted_frame['requests'] = (shifted_frame['num_requests'] - shifted_frame['num_requests_unshifted'])\n",
    "\n",
    "    return shifted_frame.loc[:, ['responsetime', 'percentile', 'requests']]\n",
    "def combine_multiple_histograms(histogram_arrays, throughputs, granularity):\n",
    "    interpolated = [interpolate_histogram(hist, granularity) for hist in histogram_arrays]\n",
    "    interpolated_with_numrequests = [calculate_numrequests(interp, xput, granularity) for interp, xput in zip(interpolated, throughputs)]\n",
    "    return pd.concat(interpolated_with_numrequests).groupby('responsetime').agg({'requests': 'sum'}).reset_index()\n",
    "\n",
    "def wquantile(x,q):           \n",
    "    xsort = x.sort_values(x.columns[0])\n",
    "    xsort['index'] = range(len(x))\n",
    "    p = q * x[x.columns[1]].sum()\n",
    "    pop = float(xsort[xsort.columns[1]][xsort['index']==0])\n",
    "    i = 0\n",
    "    while pop < p:\n",
    "        pop = pop + float(xsort[xsort.columns[1]][xsort['index']==i+1])\n",
    "        i = i + 1\n",
    "    return xsort[xsort.columns[0]][xsort['index']==i]\n",
    "\n",
    "def extract_percentiles(data, percentiles):\n",
    "    percentile_list = []\n",
    "    percentile_list.extend([(perc, wquantile(data, perc).values[0]) for perc in percentiles])\n",
    "    return pd.DataFrame(data=percentile_list, columns=['percentile', 'responsetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "run = \"writeOnly_32vc{}workers\".format(num_workers)\n",
    "inputdir = os.path.join(exp_dir, run)\n",
    "\n",
    "                        \n",
    "reps_range = range(1, 4)\n",
    "middlewares = [\"middleware_04\", \"middleware_05\"]\n",
    "reqs = gather_requests(inputdir, reps_range, middlewares)\n",
    "\n",
    "# Extracting histograms for Sharded\n",
    "client_logfiles = [\"client_01_0.log\", \"client_01_1.log\", \"client_02_0.log\", \"client_02_1.log\", \"client_03_0.log\", \"client_03_1.log\"]\n",
    "reps = 3\n",
    "filepaths = [os.path.join(inputdir, str(rep), logfiles) for rep in range(1, reps+1) for logfiles in client_logfiles]\n",
    "histograms = [np.array(extract_GET_histogram(filepath), dtype=float) for filepath in filepaths]\n",
    "throughputs = [extract_GET_throughput(filepath) for filepath in filepaths]\n",
    "hist_data = combine_multiple_histograms(histograms, throughputs, granularity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reps = []\n",
    "for rep in reps_range:\n",
    "\n",
    "    log_folder_path = os.path.join(inputdir, str(int(rep)))\n",
    "\n",
    "    # Now we extract throughput, responsetime, average queuetime and missrate from the middleware\n",
    "    middleware_dirs = [dirfuncs.get_only_subdir(os.path.join(log_folder_path, mw_dir)) for mw_dir in middlewares]\n",
    "    concatenated_requests = [gmws.concatenate_requestlogs(middleware_dir) for middleware_dir in middleware_dirs]\n",
    "    metrics = [gmws.extract_metrics(reqs) for reqs in concatenated_requests]\n",
    "    cut_metrics = [cut.cut_away_warmup_cooldown(mets, 10, 72) for mets in metrics]\n",
    "    windows = [gmws.aggregate_over_windows(cut_mets) for cut_mets in cut_metrics]\n",
    "    rep_metrics = gmws.aggregate_over_middlewares(windows)\n",
    "    all_reps.append(rep_metrics)\n",
    "\n",
    "mw_agg_over_reps = gmws.aggregate_over_reps(all_reps)\n",
    "mw_averages = gmws.aggregate_over_timesteps(mw_agg_over_reps)\n",
    "avg = mw_averages.loc['mean', :]\n",
    "\n",
    "all_rep_windows = []\n",
    "for rep in reps_range:\n",
    "\n",
    "    log_folder_path = os.path.join(inputdir, str(rep))\n",
    "\n",
    "    client_logfile_paths = [os.path.join(log_folder_path, client_logfile) for client_logfile in client_logfiles]\n",
    "    window = gmts.aggregate_over_clients(client_logfile_paths)\n",
    "    window = cut.cut_away_warmup_cooldown(window, 10, 72)\n",
    "    all_rep_windows.append(window)\n",
    "\n",
    "mt_agg_over_reps = gmts.aggregate_over_reps(all_rep_windows)\n",
    "mt_averages = gmts.aggregate_over_timesteps(mt_agg_over_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = num_workers * 2\n",
    "def calculate_prob_zero_jobs(rho, m):\n",
    "    return 1 / (1 + ((m*rho)**m)/(math.factorial(m)*(1-rho)) + sum([(m*rho)**n/math.factorial(n) for n in range(1, m)]))\n",
    "    \n",
    "arrivalrate_lambda = mt_averages.loc['mean', 'throughput']\n",
    "servicetime_ms = (reqs['workerPreProcessingTime_ms'] + reqs['memcachedRTT_ms'] + reqs['workerPostProcessingTime_ms']).mean()\n",
    "servicerate_mu = 1000/servicetime_ms\n",
    "trafficIntensity_rho = arrivalrate_lambda / (m * servicerate_mu) # == average utilization of each server\n",
    "interarrivalTime_tao = 1000 / arrivalrate_lambda\n",
    "probability_zero_jobs = calculate_prob_zero_jobs(trafficIntensity_rho, m)\n",
    "probability_of_queueing = ((m*trafficIntensity_rho)**m)/(math.factorial(m)*(1-trafficIntensity_rho))*probability_zero_jobs\n",
    "mean_number_jobs_in_system = m*trafficIntensity_rho + trafficIntensity_rho*probability_of_queueing / (1-trafficIntensity_rho)# Compare with worker count\n",
    "mean_number_jobs_in_queue = trafficIntensity_rho*probability_of_queueing/(1-trafficIntensity_rho) # Compare with worker count\n",
    "mean_response_time_r = 1000/servicerate_mu * (1 + probability_of_queueing/(m*(1-trafficIntensity_rho))) # Compare with mean response time of client or middleware\n",
    "mean_waiting_time_w = 1000*probability_of_queueing / (m*servicerate_mu*(1-trafficIntensity_rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Arrival Rate Lambda: Predicted: {}, Actual Throughput: {}\".format(arrivalrate_lambda, mt_averages.loc['mean', 'throughput']))\n",
    "print(\"Service Rate Mu: Predicted: {}\".format(servicerate_mu))\n",
    "print(\"Traffic Intensity rho / Utilization per server: Predicted: {:0.4f}\".format(trafficIntensity_rho))\n",
    "print(\"Interarrival Time: Predicted: {:0.4f}, Actual interarrival time: {:0.4f}\".format(interarrivalTime_tao, reqs['interarrivalTime_ms'].mean()))\n",
    "print(\"Worker Service Time: Predicted: {:0.4f}, Actual worker service time: {:0.4f}\".format(servicetime_ms, servicetime_ms))\n",
    "print(\"Probability zero jobs: Predicted: {:0.4f}\".format(probability_zero_jobs))\n",
    "print(\"Probability of queueing: Predicted: {:0.4f}\".format(probability_of_queueing))\n",
    "print(\"Number of Jobs in System: Predicted: {:0.4f}, Actual Num workers in the queue: {:0.4f}\".format(mean_number_jobs_in_system, (num_workers*2*trafficIntensity_rho+avg['queueLength'])))\n",
    "print(\"Number of Jobs in Queue: Predicted: {:0.4f}, Actual Queue Length: {:0.4f}\".format(mean_number_jobs_in_queue, avg['queueLength']))\n",
    "print(\"Mean Response Time r: Predicted: {:0.4f}, Actual Response Time (Middleware): {:0.4f}\".format(mean_response_time_r, avg['responseTime_ms']))\n",
    "print(\"Mean Waiting Time w: Predicted: {:0.4f}, Actual Queue Waiting Time: {:0.4f}\".format(mean_waiting_time_w, avg['queueTime_ms']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
