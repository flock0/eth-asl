{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_format = '%d-%m %H:%M:%S'\n",
    "def extract_startend_times(inputdir, rep, dstat_filename, truncate_sec):\n",
    "    # create filepath\n",
    "    filepath = os.path.join(inputdir, str(rep), dstat_filename)\n",
    "    csv_file = pd.read_csv(filepath, header=3)\n",
    "    \n",
    "    start_time = csv_file['time'].min()\n",
    "    end_time = csv_file['time'].max()\n",
    "    parsed_start_time = datetime.datetime.strptime(start_time, time_format)\n",
    "    parsed_end_time = datetime.datetime.strptime(end_time, time_format)\n",
    "    truncated_start_time = parsed_start_time + datetime.timedelta(0,truncate_sec)\n",
    "    truncated_end_time = parsed_end_time - datetime.timedelta(0,truncate_sec)\n",
    "    truncated_start_string = truncated_start_time.strftime(time_format)\n",
    "    truncated_end_string = truncated_end_time.strftime(time_format)\n",
    "    return (truncated_start_string, truncated_end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dstat_from_server(experiment_dir, server_dstat_filename, startend_times_tuple):\n",
    "    start_string = startend_times_tuple[0]\n",
    "    end_string = startend_times_tuple[1]\n",
    "    \n",
    "    filepath = os.path.join(experiment_dir, server_dstat_filename)\n",
    "    csv_file = pd.read_csv(filepath, header=3)\n",
    "    \n",
    "    truncated_data = csv_file[(csv_file['time'] >= start_string) & (csv_file['time'] <= end_string)]\n",
    "    \n",
    "    excerp = truncated_data.loc[:, ['idl', 'recv', 'send']]\n",
    "    means = excerp.mean()\n",
    "    means['load'] = 100 - means['idl']\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_server_dstat_all_reps(experiment_dir, reps, client_dstat_filename, server_dstat_filename, truncate_sec):\n",
    "    rep_time_tuples = [extract_startend_times(inputdir, rep, client_dstat_filename, truncate_sec) for rep in range(1, reps+1)]\n",
    "    all_reps = [read_dstat_from_server(experiment_dir, server_dstat_filename, tup) for tup in rep_time_tuples]\n",
    "    result = pd.concat(all_reps, axis='columns').mean(axis='columns')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dstat_all_servers(experiment_dir, reps, client_dstat_filename, server_dstat_filenames, truncate_sec):\n",
    "    all_servers = [read_server_dstat_all_reps(experiment_dir, reps, client_dstat_filename, filename, truncate_sec) for filename in server_dstat_filenames]\n",
    "    result = pd.concat(all_servers, axis='columns')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_dstat_servers(data, mean_columns):\n",
    "    return data.loc[mean_columns, :].mean(axis='columns')\n",
    "\n",
    "def sum_dstat_servers(data, sum_columns):\n",
    "    return data.loc[sum_columns, :].sum(axis='columns')\n",
    "\n",
    "def aggregate_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec):\n",
    "    data = read_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec)\n",
    "    means = mean_dstat_servers(data, ['load'])\n",
    "    sums = sum_dstat_servers(data, ['recv', 'send'])\n",
    "    return pd.concat([means, sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"\" # 2.1 experiment dir\n",
    "workloads = [\"readOnly\", \"writeOnly\"]\n",
    "vcs = [1, 4, 8, 16, 32, 64, 128, 256]\n",
    "dstat_filename = \"client_dstat_01.log\"\n",
    "server_dstat_filenames = [\"server_dstat_06.log\"]\n",
    "reps = 3\n",
    "truncate_sec = 0\n",
    "num_threads = 6\n",
    "\n",
    "all_metrics = []\n",
    "for vc in vcs:\n",
    "    for wl in workloads:\n",
    "        inputdir = os.path.join(experiment_dir, \"{}_{}vc\".format(wl, vc))\n",
    "        metrics = aggregate_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec)\n",
    "        metrics['num_clients'] = vc * num_threads\n",
    "        metrics['workload'] = wl\n",
    "        all_metrics.append(metrics)\n",
    "nice_table = pd.concat(all_metrics, axis=1).transpose()\n",
    "nice_table['recv'] = nice_table['recv'] / 1000000\n",
    "nice_table['send'] = nice_table['send'] / 1000000\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim([0, 15])\n",
    "ax.set_xlim([0, 220])\n",
    "ax.set_prop_cycle(cycler('color',['#a6611a', '#018571']))\n",
    "for key, grp in nice_table.groupby(['workload']):\n",
    "    grp.plot(ax=ax, x='num_clients', y='send', label=key, marker='o')\n",
    "ax.legend(loc=\"best\", fontsize=\"small\")\n",
    "ax.set_title(\"Send network activity of the memcached VM\")\n",
    "ax.set_xlabel(\"Number of clients\")\n",
    "ax.set_ylabel(\"Send Throughput (MB/s)\")\n",
    "plt.axhline(y=12,hold=None, color='r')\n",
    "plt.show()\n",
    "fig.savefig(\"./2_1_memcached_Send.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim([0, 110])\n",
    "ax.set_xlim([0, 800])\n",
    "ax.set_prop_cycle(cycler('color',['#a6611a', '#018571']))\n",
    "for key, grp in nice_table.groupby(['workload']):\n",
    "    grp.plot(ax=ax, x='num_clients', y='load', label=key, marker='o')\n",
    "ax.legend(loc=\"best\", fontsize=\"small\")\n",
    "ax.set_title(\"CPU load on the memcached VM\")\n",
    "ax.set_xlabel(\"Number of clients\")\n",
    "ax.set_ylabel(\"Send Throughput (MB/s)\")\n",
    "plt.show()\n",
    "fig.savefig(\"./2_1_memcached_Load.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"\" # 2.2 experiment dir\n",
    "workloads = [\"readOnly\", \"writeOnly\"]\n",
    "vcs = [1, 4, 8, 16, 32, 64, 128, 256]\n",
    "dstat_filename = \"client_dstat_01.log\"\n",
    "server_dstat_filenames = [\"server_dstat_06.log\", \"server_dstat_07.log\"]\n",
    "reps = 3\n",
    "truncate_sec = 0\n",
    "num_threads = 2\n",
    "\n",
    "all_metrics = []\n",
    "for vc in vcs:\n",
    "    for wl in workloads:\n",
    "        inputdir = os.path.join(experiment_dir, \"{}_{}vc\".format(wl, vc))\n",
    "        metrics = aggregate_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec)\n",
    "        metrics['num_clients'] = vc * num_threads\n",
    "        metrics['workload'] = wl\n",
    "        all_metrics.append(metrics)\n",
    "nice_table = pd.concat(all_metrics, axis=1).transpose()\n",
    "nice_table['recv'] = nice_table['recv'] / 1000000\n",
    "nice_table['send'] = nice_table['send'] / 1000000\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#ax.set_ylim([0, 15])\n",
    "ax.set_xlim([0, 300])\n",
    "ax.set_prop_cycle(cycler('color',['#a6611a', '#018571']))\n",
    "for key, grp in nice_table.groupby(['workload']):\n",
    "    grp.plot(ax=ax, x='num_clients', y='load', label=key, marker='o')\n",
    "ax.legend(loc=\"best\", fontsize=\"small\")\n",
    "ax.set_title(\"Send network activity of the memcached VM\")\n",
    "ax.set_xlabel(\"Number of clients\")\n",
    "ax.set_ylabel(\"Send Throughput (MB/s)\")\n",
    "#plt.axhline(y=12,hold=None, color='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
