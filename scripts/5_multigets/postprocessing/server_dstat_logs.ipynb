{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_format = '%d-%m %H:%M:%S'\n",
    "def extract_startend_times(inputdir, rep, dstat_filename, truncate_sec):\n",
    "    # create filepath\n",
    "    filepath = os.path.join(inputdir, str(rep), dstat_filename)\n",
    "    csv_file = pd.read_csv(filepath, header=3)\n",
    "    \n",
    "    start_time = csv_file['time'].min()\n",
    "    end_time = csv_file['time'].max()\n",
    "    parsed_start_time = datetime.datetime.strptime(start_time, time_format)\n",
    "    parsed_end_time = datetime.datetime.strptime(end_time, time_format)\n",
    "    truncated_start_time = parsed_start_time + datetime.timedelta(0,truncate_sec)\n",
    "    truncated_end_time = parsed_end_time - datetime.timedelta(0,truncate_sec)\n",
    "    truncated_start_string = truncated_start_time.strftime(time_format)\n",
    "    truncated_end_string = truncated_end_time.strftime(time_format)\n",
    "    return (truncated_start_string, truncated_end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dstat_from_server(experiment_dir, server_dstat_filename, startend_times_tuple):\n",
    "    start_string = startend_times_tuple[0]\n",
    "    end_string = startend_times_tuple[1]\n",
    "    \n",
    "    filepath = os.path.join(experiment_dir, server_dstat_filename)\n",
    "    csv_file = pd.read_csv(filepath, header=3)\n",
    "    \n",
    "    truncated_data = csv_file[(csv_file['time'] >= start_string) & (csv_file['time'] <= end_string)]\n",
    "    \n",
    "    excerp = truncated_data.loc[:, ['idl', 'recv', 'send']]\n",
    "    means = excerp.mean()\n",
    "    means['load'] = 100 - means['idl']\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_server_dstat_all_reps(experiment_dir, reps, client_dstat_filename, server_dstat_filename, truncate_sec):\n",
    "    rep_time_tuples = [extract_startend_times(inputdir, rep, client_dstat_filename, truncate_sec) for rep in range(1, reps+1)]\n",
    "    all_reps = [read_dstat_from_server(experiment_dir, server_dstat_filename, tup) for tup in rep_time_tuples]\n",
    "    result = pd.concat(all_reps, axis='columns').mean(axis='columns')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_server_dstat_all_reps_noavg(experiment_dir, reps, client_dstat_filename, server_dstat_filename, truncate_sec):\n",
    "    rep_time_tuples = [extract_startend_times(inputdir, rep, client_dstat_filename, truncate_sec) for rep in range(1, reps+1)]\n",
    "    all_reps = [read_dstat_from_server(experiment_dir, server_dstat_filename, tup) for tup in rep_time_tuples]\n",
    "    result = pd.concat(all_reps, axis='columns')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dstat_all_servers(experiment_dir, reps, client_dstat_filename, server_dstat_filenames, truncate_sec):\n",
    "    all_servers = [read_server_dstat_all_reps(experiment_dir, reps, client_dstat_filename, filename, truncate_sec) for filename in server_dstat_filenames]\n",
    "    result = pd.concat(all_servers, axis='columns')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_dstat_servers(data, mean_columns):\n",
    "    return data.loc[mean_columns, :].mean(axis='columns')\n",
    "\n",
    "def sum_dstat_servers(data, sum_columns):\n",
    "    return data.loc[sum_columns, :].sum(axis='columns')\n",
    "\n",
    "def aggregate_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec):\n",
    "    data = read_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec)\n",
    "    means = mean_dstat_servers(data, ['load'])\n",
    "    sums = sum_dstat_servers(data, ['recv', 'send'])\n",
    "    return pd.concat([means, sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_dir = \"\" # 5.2 nonsharded experiment dir\n",
    "sharded = \"nonsharded\"\n",
    "#experiment_dir = \"/home/flo/Documents/eth-asl-final-experiment-data/exp5/5_1_multigets_sharded_2017-11-24_085912\"\n",
    "#sharded = \"sharded\"\n",
    "\n",
    "multigets = [1, 3, 6, 9]\n",
    "\n",
    "dstat_filename = \"client_dstat_01.log\"\n",
    "server_dstat_filenames = [\"server_dstat_06.log\", \"server_dstat_07.log\"]\n",
    "reps = 3\n",
    "truncate_sec = 5\n",
    "\n",
    "all_metrics = []\n",
    "for multiget in multigets:\n",
    "    inputdir = os.path.join(experiment_dir, \"{}_{}multiget\".format(sharded, multiget))\n",
    "    single_metrics = read_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec)\n",
    "    metrics = aggregate_dstat_all_servers(experiment_dir, reps, dstat_filename, server_dstat_filenames, truncate_sec)\n",
    "    metrics['multigets'] = multiget\n",
    "    all_metrics.append(metrics)\n",
    "agg_table = pd.concat(all_metrics, axis=1).transpose()\n",
    "agg_table['recv'] = agg_table['recv'] / 1000000\n",
    "agg_table['send'] = agg_table['send'] / 1000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "color_cycler = cycler('color', ['#ccece6', '#66c2a4', '#238b45', '#00441b'])\n",
    "ax.set_ylim([0, 30])\n",
    "#ax.set_xlim([0, 400])\n",
    "ax.set_prop_cycle(color_cycler)\n",
    "agg_table.plot(ax=ax, x='multigets', y='load', marker='o')\n",
    "#plt.xticks(multigets)\n",
    "ax.legend(loc=\"best\", fontsize=\"small\")\n",
    "ax.set_xlabel(\"Number of clients\")\n",
    "ax.set_ylabel(\"Throughput (MB/s)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
